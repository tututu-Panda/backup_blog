---
title: 随机梯度下降法
tags: [最优化,梯度下降]
toc: true
grammar_cjkRuby: true
grammar_highlight: true
mathjax: true
---

## 是什么

> 什么是随机梯度下降法？

随机采取一个样本的方式进行函数更新，拟合函数关系。这种方式就被称为随机梯度下降。

<!--more-->

## 为什么

> 为什么这样做？

1. 所有的样本数据初试时便符合一定的函数关系。随机选取一个，来预测当前的误差，根据误差来拟合函数，其更新速度相较于批量更快。

> 实现原理？

1. 首先更新某个点时，用一个样本进行更新时的公式：

$$
\theta_{j} :=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J(\theta)
$$

其中$$\theta_{j}$$为最开始的随机初始点，$$\alpha$$为下降最大方向的步伐大小。$$\frac{\partial}{\partial \theta_{j}} J(\theta)$$为函数的偏导数。

2. **随机选择一个点，进行同样的更新：**

$$
\theta_{j} :=\theta_{j}-\alpha \frac{\partial}{\partial \theta_{j}} J(\theta)
$$

3. **重复样本数据，直到循环次数达到限制或者满足某个值时为止。**

## 优缺点

> 优点

1. 参数更新较快。

> 缺点

1. 由于是随机的样本，因此参数更新的方向不一定正确。
2. 容易陷入局部极小值。